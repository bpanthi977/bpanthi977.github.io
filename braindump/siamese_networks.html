<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Siamese Networks</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="H" href="./index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-04-01 Sat]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">Siamese Networks</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#SimSiam%3A%20Exploring%20Simple%20Siamese%20Representation%20Learning">1. SimSiam: Exploring Simple Siamese Representation Learning</a></li>
<li><a href="#Thoughts">2. Thoughts</a></li>
</ul>
</div>
</div>
<div id="outline-container-SimSiam%3A%20Exploring%20Simple%20Siamese%20Representation%20Learning" class="outline-2">
<h2 id="SimSiam%3A%20Exploring%20Simple%20Siamese%20Representation%20Learning"><span class="section-number-2">1.</span> SimSiam: Exploring Simple Siamese Representation Learning</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="papers/Exploring Simple Siamese Representation Learning - 2011.10566.pdf">Exploring Simple Siamese Representation Learning - 2011.10566</a>
</p>


<div id="figure-1" class="figure">
<p><img src="data/siamese_networks/simsiam-20230401152441.png" alt="simsiam-20230401152441.png" />
</p>
<p><span class="figure-number">Figure 1: </span>SimSiam</p>
</div>

<ul class="org-ul">
<li>uses stop-gradient operator (aka. tensor.detach())</li>
<li><p>
The loss function is: 
</p>

<p>
\(L = \frac 1 2 D(p_1, z_2) + \frac 1 2 D(p_2, z_1)\)
</p>

<p>
where, \(z_1\) and \(z_1\) held constant (i.e. stop gradient) are the representation of the input \(x\), and \(p_1\) and \(p_2\) are the prediction of the representation.
</p></li>
</ul>



<ul class="org-ul">
<li><p>
This loss function, as hypothesized by the authors, optimizes for the following objective:
</p>

<p>
\(L(\theta, \eta) = E_{x,T} \big[ || F_{\theta}(T(x)) - \eta_x ||_2^2 \big]\)
</p>

<p>
where, \(F_{\theta}\) is a network, \(T\) is an augmentation, \(x\) is an image and \(\eta_x\) is intended to be the representation of the image \(x\).
</p>

<p>
This optimization can be done is two-step iterations: 
</p>
<ol class="org-ol">
<li>Optmizing \(F_{\theta}\) while keeping \(\eta_x\) constant</li>

<li><p>
Then, optimizing \(\eta_x\) keeping \(F_{\theta}\) constant.
</p>

<p>
See section 5 of the paper at pg. 5. It has a nicely written interesting argument and supporting evidence. 
</p></li>
</ol>

<p>
I find this similar to the <a href="generalized_policy_iteration.html#ID-A656C5E5-414A-4D36-8877-B6755BDEDF4F">Generalized Policy Iteration</a> in Reinforcement Learning.
</p></li>

<li>The <a href="representation_learning.html#ID-5472BE86-3F85-4968-85F7-BF29128B8319">representation</a> learned are found to be transferable across tasks. Increasing the approach's utility for <a href="transfer_learning.html#ID-09DAC3D5-724B-4683-A758-4CEB16A0ADAD">Transfer Learning</a>.</li>
</ul>
</div>
</div>
<div id="outline-container-Thoughts" class="outline-2">
<h2 id="Thoughts"><span class="section-number-2">2.</span> Thoughts</h2>
</div>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: Siamese Networks">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div>
</div>
</body>
</html>
