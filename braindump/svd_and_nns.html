<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>SVD and NNs</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="./index.html"> UP </a>
 |
 <a accesskey="H" href="../index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">&lt;2024-11-13 Wed&gt;</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">SVD and NNs</h1>
<p>
In connection to <a href="neural_network.html#ID-EFC67D0C-407F-4E53-A91E-64E6256C856E">Neural Networks</a> and <a href="singular_value_decomposition.html#ID-00F5D0F8-ADA4-4F96-9DFC-2A87FD6E37C5">SVD</a> there has been some research. Mostly (so far as  I have found) in the direction of using SVD to improve certain aspects of NNs:
</p>

<ol class="org-ol">
<li><sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup> Represents weight matrix as SVD . This has <a href="https://arxiv.org/abs/1803.09327">uses</a> in training RNNs to stabilize gradients,</li>
<li><sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup> Computes initialization for Neural Network Parameters using SVD of data. But this is only for single layer NNs.</li>
<li><sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup> Uses SVD representation of Weights to train a CNN and get a low rank NNs. Useful for model compression. But uses regularization to ensure orthogonality (using technique from <sup><a id="fnr.1.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup> would have been better)</li>
</ol>

<p>
There is some research regarding computing spectral parameters using Neural Networks too:
</p>

<ol class="org-ol">
<li><sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup> Trains NNs to predict Singular Values. But only singluar values, not vectors. And the experiments are for small matrices.</li>
<li><sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup> Uses Neural Network to find singular values and singular functions of linear operators. In the paper they find orbitals of Hydrogen atoms using this method.</li>
</ol>

<p>
In overall only <sup><a id="fnr.5.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup> works towards using NNs to find singular vectors.
</p>

<p>
Other papers:
</p>
<ul class="org-ul">
<li>Deep learning combined with singular value decomposition to reconstruct databases in fluid dynamics. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423024260">https://www.sciencedirect.com/science/article/abs/pii/S0957417423024260</a></li>
</ul>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
What if Neural Networks had SVDs?, <a href="https://proceedings.neurips.cc/paper/2020/hash/d61e4bbd6393c9111e6526ea173a7c8b-Abstract.html">NeurIPS 2020</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Singular Value Decomposition and Neural Networks, <a href="https://arxiv.org/abs/1906.11755">arXiv</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality Regularization and Singular Value Sparsification, <a href="https://www2.cs.uh.edu/~fyan/Paper/Feng-CVPRW20.pdf">CVPR Workshop</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
SV-Learn: Learning Matrix Singular Values with Neural Networks, <a href="https://ieeexplore.ieee.org/document/10031050">International Conference on Data Mining Workshop</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Operator SVD with Neural Networks via Nested Low-Rank Approximation, <a href="https://arxiv.org/abs/2402.03655">ICML 2024</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: SVD and NNs">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div>
</div>
</body>
</html>
