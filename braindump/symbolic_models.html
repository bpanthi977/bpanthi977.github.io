<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Symbolic Models</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="H" href="./index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-01-01 Sun]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">Symbolic Models</h1>
<p>
<a href="https://github.com/openai/whisper">https://github.com/openai/whisper</a>
</p>

<p>
The presenter of this talk (<a href="https://www.youtube.com/watch?v=wmQIcTOzH0k">https://www.youtube.com/watch?v=wmQIcTOzH0k</a>)
</p>
<ul class="org-ul">
<li>explains his paper (<a href="https://arxiv.org/abs/2006.11287">Discovering Symbolic Models from Deep Learning with Inductive Biases 2006.11287</a>)</li>
<li>why symbolic regression should be 1st class ML algorithms in Astrophysics</li>
<li>how symbolic regression can be extended to high dimensional datasets</li>
</ul>


<ol class="org-ol">
<li><p>
Why Symbolic Regression?
</p>

<p>
<a href="wignerian_prior.html#ID-1B8C75DC-25E4-47E0-8F21-A9515B5C6BCF">Wignerian Prior</a> (Simple analytic equations generalize to out of distribution data.)
</p></li>

<li><p>
How to extend? 
</p>

<p>
train a model with inductive bias on the structure of the solution. i.e. train mutiple internal functions on low dimensonal space of the problem, then do symbolic regresssion on those internal function, then combine the symbolic expressions. 
</p></li>
</ol>


<p>
Authors: Miles Cranmer, Alvaro Sanchez-Gonzalez, Peter Battaglia, Rui Xu, Kyle Cranmer, David Spergel, Shirley Ho
</p>

<p>
Abstract: We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example-a detailed dark matter simulation-and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distribution data better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.
</p>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: Symbolic Models">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div>
</div>
</body>
</html>
