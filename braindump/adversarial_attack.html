<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Adversarial Attack</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="H" href="./index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-07-23 Sun]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">Adversarial Attack</h1>
<p>
Someone trained an adversial network to beat an existing superhuman <a href="artificial_intelligence.html#ID-2674491f-a645-4499-996e-af04db2be74d">AI</a>, and then it found out how to beat that AI. The adversial network is different from normal Go programs in that it wasn't trained to play the best <a href="go.html#ID-0B2EB862-26D1-4ED2-BF63-52B19F9D4A65">Go</a>, instead it was trained to beat the specific victim AI.  (e.g. 
<a href="private/The Evolution of AlphaGo to MuZero.html#ID-683F6DDF-84D4-480B-ABF5-684512B8876B">AlphaZero</a>) (<a href="https://twitter.com/farairesearch/status/1682150899853193216">https://twitter.com/farairesearch/status/1682150899853193216</a>)
</p>


<div id="figure-1" class="figure">
<p><img src="data/adversarial_attack/adversarial_training_on_katago_using_alphazero_like_algorithm-20230723103537.png" alt="adversarial_training_on_katago_using_alphazero_like_algorithm-20230723103537.png" />
</p>
<p><span class="figure-number">Figure 1: </span>Adversarial training on KataGo using AlphaZero like algorithm</p>
</div>

<p>
The key takeaway from this is that (<a href="https://twitter.com/ARGleave/status/1587875117798813697">https://twitter.com/ARGleave/status/1587875117798813697</a>)
</p>
<blockquote>
<p>
Our key takeaway is that even AI systems that match or surpass human-level performance in common cases can have surprising failure modes quite unlike humans. <b>We'd recommend broader use of adversarial testing to find these failure modes, especially in safety-critical systems</b>.
</p>
</blockquote>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: Adversarial Attack">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div>
</div>
</body>
</html>
