<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>RL can be used to train Non-Differentiable Models</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="H" href="./index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-03-19 Sun]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">RL can be used to train Non-Differentiable Models</h1>
<ul class="org-ul">
<li><p>
In <a href="private/the_unreasonable_effectiveness_of_recurrent_neural_networks_andrej_karpathy.html#ID-C87D99C4-20AF-4AF5-905F-ECA82BB7AB54">The Unreasonable Effectiveness of Recurrent Neural Networks - Andrej Karpathy</a>, the author writes:
</p>

<p>
My personal favorite RNNs in Computer Vision paper is Recurrent Models of Visual Attention, both due to its high-level direction (sequential processing of images with glances) and the low-level modeling (REINFORCE learning rule that is a special case of policy gradient methods in Reinforcement Learning, which allows one to train models that perform non-differentiable computation (taking glances around the image in this case)). 
</p></li>

<li>The paper <a href="papers/Computer Vision/Recurrent Models of Visual Attention - 1406.6247.pdf">Recurrent Models of Visual Attention</a>, uses <a href="reinforcement_learning.html#ID-B010228E-5555-4D07-8E63-B54E476A249E">Reinforcement Learning</a> to train an non-differential model for vision task like the MNIST digit classification. A sliding window of image region to attend to is moved by using RNN and then after \(T\) steps the digit is predicted. Attention part is trained by RL, and the prediction part is trained by traditional backpropagation.</li>

<li>The paper <a href="papers/Reinforcement Learning Neural Turing Machines - 1505.00521.pdf">Reinforcement Learning Neural Turing Machines</a> improves upon Neural Turing Machines by using a discrete memory access instead of continuous one. The control of memory location to access and write to is trained by RL.</li>
</ul>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: RL can be used to train Non-Differentiable Models">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div>
</div>
</body>
</html>
