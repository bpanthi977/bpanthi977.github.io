<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Deep Reinforcement Learning: CS 285 Fall 2021</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="./index.html"> UP </a>
 |
 <a accesskey="H" href="../index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-07-09 Sun]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">Deep Reinforcement Learning: CS 285 Fall 2021</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#Lecture%201">1. Lecture 1</a></li>
<li><a href="#%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%201%20%5C%5BJHrlF10v2Og%5C%5D.mp4%5D%5BL1P1%3A%20Introduction%5D%5D">2. L1P1: Introduction</a></li>
<li><a href="#%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%202%20%5C%5BIoF7D0qec0I%5C%5D.mp4%5D%5BL1P2%3A%20Why%20Deep%20RL%3F%5D%5D">3. L1P2: Why Deep RL?</a></li>
<li><a href="#%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%203%20%5C%5BBYoKE9yRy8g%5C%5D.mp4%5D%5BL1P3%3A%20Beyond%20learning%20from%20Reward%5D%5D">4. L1P3: Beyond learning from Reward</a></li>
<li><a href="#%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%204%20%5C%5BxRmBEnI55es%5C%5D.mp4%5D%5BL1P4%3A%20How%20do%20we%20build%20intelligent%20machines%3F%5D%5D">5. L1P4: How do we build intelligent machines?</a></li>
<li><a href="#Lecture%202">6. Lecture 2</a>
<ul>
<li><a href="#%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%202%2C%20Part%201%20%5C%5BHUzyjOsd2PA%5C%5D.mp4%5D%5BL2P1%3A%20Supervised%20Learning%20of%20Behaviours%5D%5D">6.1. L2P1: Supervised Learning of Behaviours</a></li>
<li><a href="#%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%202%2C%20Part%202%20%5C%5B988gLurg01U%5C%5D.mp4%5D%5BL2P2%5D%5D">6.2. L2P2</a></li>
</ul>
</li>
<li><a href="#Links">7. Links</a></li>
</ul>
</div>
</div>
<p>
by <a href="sergey_levine.html#ID-65DED394-F17D-4C6A-A86D-FE48A5EED74A">Sergey Levine</a>
</p>

<div id="outline-container-Lecture%201" class="outline-2">
<h2 id="Lecture%201"><span class="section-number-2">1.</span> Lecture 1</h2>
</div>
<div id="outline-container-%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%201%20%5C%5BJHrlF10v2Og%5C%5D.mp4%5D%5BL1P1%3A%20Introduction%5D%5D" class="outline-2">
<h2 id="%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%201%20%5C%5BJHrlF10v2Og%5C%5D.mp4%5D%5BL1P1%3A%20Introduction%5D%5D"><span class="section-number-2">2.</span> <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 1 [JHrlF10v2Og].mp4">L1P1: Introduction</a></h2>
<div class="outline-text-2" id="text-2">

<div id="org439e912" class="figure">
<p><img src="data/deep_reinforcement_learning_cs_285_fall_2021/how_is_rl_different_from_other_ml-20230709120854.png" alt="how_is_rl_different_from_other_ml-20230709120854.png" />
</p>
<p><span class="figure-number">Figure 1: </span>How is RL different from other ML</p>
</div>

<p>
RL is different
</p>
<ul class="org-ul">
<li>because data is not i.i.d</li>
<li>ground truth answer is not know</li>
</ul>

<p>
RL is not just for games and robots. 
</p>
<ul class="org-ul">
<li>traffic control (by Cathy Wu) <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 1 [JHrlF10v2Og].mp4::00:09:15">00:09:15</a></li>
</ul>
</div>
</div>

<div id="outline-container-%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%202%20%5C%5BIoF7D0qec0I%5C%5D.mp4%5D%5BL1P2%3A%20Why%20Deep%20RL%3F%5D%5D" class="outline-2">
<h2 id="%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%202%20%5C%5BIoF7D0qec0I%5C%5D.mp4%5D%5BL1P2%3A%20Why%20Deep%20RL%3F%5D%5D"><span class="section-number-2">3.</span> <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 2 [IoF7D0qec0I].mp4">L1P2: Why Deep RL?</a></h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>because intelligent agents need to adapt <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 2 [IoF7D0qec0I].mp4::00:00:40">00:00:40</a></li>
<li>deep learning helps us handle unstructured environment <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 2 [IoF7D0qec0I].mp4::00:02:19">00:02:19</a></li>
<li>RL provides formalism for behavior <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 2 [IoF7D0qec0I].mp4::00:03:23">00:03:23</a></li>
</ul>



<div id="org7d29e79" class="figure">
<p><img src="data/deep_reinforcement_learning_cs_285_fall_2021/deep_rl_allow_end_to_end_learning-20230709121659.png" alt="deep_rl_allow_end_to_end_learning-20230709121659.png" />
</p>
<p><span class="figure-number">Figure 2: </span>Deep RL allow End-to-End Learning</p>
</div>

<ul class="org-ul">
<li>Recognition part of problem and Control part of problem can work together <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 2 [IoF7D0qec0I].mp4::00:07:49">00:07:49</a></li>
</ul>


<p>
Why study this now? <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 2 [IoF7D0qec0I].mp4::00:12:03">00:12:03</a>
</p>
<ul class="org-ul">
<li>advancement in RL</li>
<li>advancement in Deep Learning</li>
<li>computation power</li>
</ul>



<div id="org9570a80" class="figure">
<p><img src="data/deep_reinforcement_learning_cs_285_fall_2021/rl_is_not_new-20230709122018.png" alt="rl_is_not_new-20230709122018.png" />
</p>
<p><span class="figure-number">Figure 3: </span>RL is not new</p>
</div>
</div>
</div>

<div id="outline-container-%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%203%20%5C%5BBYoKE9yRy8g%5C%5D.mp4%5D%5BL1P3%3A%20Beyond%20learning%20from%20Reward%5D%5D" class="outline-2">
<h2 id="%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%203%20%5C%5BBYoKE9yRy8g%5C%5D.mp4%5D%5BL1P3%3A%20Beyond%20learning%20from%20Reward%5D%5D"><span class="section-number-2">4.</span> <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4">L1P3: Beyond learning from Reward</a></h2>
<div class="outline-text-2" id="text-4">
<p>
Maximizing rewards is not the only problem that matter for sequential decision making: <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4::00:00:59">00:00:59</a>
</p>
<ul class="org-ul">
<li>Inverse RL: Learning Reward Functions from examples</li>
<li>Transfer Learning, Meta-Learning: Transferring knowledge between domains</li>
<li>Learning to predict and using prediction to act</li>
</ul>


<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4::00:03:13">00:03:13 Where do rewards come from?</a>
</p>
<blockquote>
<p>
As human agents, we are accustomed to operating with rewards that are so sparse that we only experience them once or twice in a lifetime, if at all.
</p>
</blockquote>


<div id="orgc0de77d" class="figure">
<p><img src="data/deep_reinforcement_learning_cs_285_fall_2021/source_of_rewards-20230709122525.png" alt="source_of_rewards-20230709122525.png" />
</p>
<p><span class="figure-number">Figure 4: </span>Source of Rewards</p>
</div>

<p>
Other form of supervision:
</p>
<ul class="org-ul">
<li>Learning from demonstration
<ul class="org-ul">
<li>Directly copying observed behavior (<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4::00:05:17">00:05:17</a>)</li>
<li>Inferring rewards from observed behavior (<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4::00:05:51">00:05:51</a>, <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4::00:06:30">00:06:30</a>)</li>
</ul></li>
<li>Learning from observing the world 
<ul class="org-ul">
<li>Learning to predict (<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 3 [BYoKE9yRy8g].mp4::00:07:03">00:07:03</a> model based RL)</li>
<li>Unsupervised learning</li>
</ul></li>
<li>Learning from other tasks
<ul class="org-ul">
<li>Transfer learning</li>
<li>Meta-learning: learning to learn</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%204%20%5C%5BxRmBEnI55es%5C%5D.mp4%5D%5BL1P4%3A%20How%20do%20we%20build%20intelligent%20machines%3F%5D%5D" class="outline-2">
<h2 id="%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%201%2C%20Part%204%20%5C%5BxRmBEnI55es%5C%5D.mp4%5D%5BL1P4%3A%20How%20do%20we%20build%20intelligent%20machines%3F%5D%5D"><span class="section-number-2">5.</span> <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4">L1P4: How do we build intelligent machines?</a></h2>
<div class="outline-text-2" id="text-5">
<p>
Ideas
</p>
<ul class="org-ul">
<li><a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:01:22">Learning as basis of intelligence</a></li>
<li>An algorithm for each "module" of brain? or a single flexible algorithm?  <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:03:55">00:03:55</a>
<ul class="org-ul">
<li>Brain is flexible: Seeing with your tongue (humans can learn to see in some extend using tongue <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:04:38">00:04:38</a>)</li>
</ul></li>
</ul>


<p>
Some evidence in favour of deep learning
</p>
<ul class="org-ul">
<li>DeepRL learns features simlar to found in brain for touch and vision <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:07:20">00:07:20</a></li>
<li>RL is observed in brain (Basal gaglia ~= reward system) <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:08:00">00:08:00</a></li>
</ul>

<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:09:05">What can RL do well now</a>?
</p>
<ul class="org-ul">
<li>High proficiency in domains with simple rules (go, atari,)</li>
<li>Learn simple skills with raw sensory inputs (robots,)</li>
<li>Learn from imitating human provided expert behavior (driving,)</li>
</ul>

<p>
But, human are better
</p>
<ul class="org-ul">
<li>can learn incredibly quickly,</li>
<li>can reuse past knowledge</li>
<li>not clear what the reward function should be</li>
<li>not clear what the role of prediction should be <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 1, Part 4 [xRmBEnI55es].mp4::00:10:19">00:10:19</a></li>
</ul>
</div>
</div>


<div id="outline-container-Lecture%202" class="outline-2">
<h2 id="Lecture%202"><span class="section-number-2">6.</span> Lecture 2</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%202%2C%20Part%201%20%5C%5BHUzyjOsd2PA%5C%5D.mp4%5D%5BL2P1%3A%20Supervised%20Learning%20of%20Behaviours%5D%5D" class="outline-3">
<h3 id="%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%202%2C%20Part%201%20%5C%5BHUzyjOsd2PA%5C%5D.mp4%5D%5BL2P1%3A%20Supervised%20Learning%20of%20Behaviours%5D%5D"><span class="section-number-3">6.1.</span> <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4">L2P1: Supervised Learning of Behaviours</a></h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>In RL we deal with sequential decision making problems.</li>
<li>We can predict action in place of the classes (as in supervised classification problem)</li>
<li>s<sub>t</sub> : state  - markovian state</li>
<li>o<sub>t</sub> : observation - can be incomplete</li>
<li><a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:08:36">00:08:36</a> If you are using observation past observation may give you extra information because information is incomplete. And only state is markovian, observation need not be.</li>
</ul>

<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:10:18">00:10:18 Imitation Learning</a> or behavioral cloning
</p>

<ul class="org-ul">
<li>ALVINN: Autonomous Land Vehicle In a Neural Network was one of the first imitation learning system for AV <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:12:32">00:12:32</a></li>

<li>In general Imitation Learning doesn't work, although supervised learning works in other problem. This is because the policy can deviate slightly from training trajectory and then when in the new state it has higher chance of making more mistakes.</li>
</ul>


<div id="org578b506" class="figure">
<p><img src="data/deep_reinforcement_learning_cs_285_fall_2021/problem_with_imitation_learning-20230710082620.png" alt="problem_with_imitation_learning-20230710082620.png" />
</p>
<p><span class="figure-number">Figure 5: </span>Problem with Imitation Learning</p>
</div>

<ul class="org-ul">
<li><p>
but after a lot of data, it <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:14:50">00:14:50</a> works. In this particular case (NVIDIA's autonomous driving) because of techniques used in training:
</p>

<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:16:59">00:16:59</a> The general principle is to modify you training data to illustrate the mistakes and shows how to correct them, then the policy might learn to be more robust. 
</p></li>

<li><p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:18:43">00:18:43</a> The problem with Imitation Learning is that the training data distribution is different from test distribution \(p_{\pi}(o_t)\) is different from \(p_{data}(o_t)\)
</p>

<p>
So, Can we make those distribution more close? 
</p>
<ul class="org-ul">
<li>Yes. If we make the policy perfect. But that's difficult.</li>
<li><p>
Instead make the data distribution closer to test distribution. 
</p>

<p>
DAgger: Dataset Aggregation <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 1 [HUzyjOsd2PA].mp4::00:20:29">00:20:29</a>: Collect training data from \(p_{\pi}(o_t)\) 
</p>
<ul class="org-ul">
<li>run the policy</li>
<li>label the data</li>
<li>train with aggregated data</li>
<li>repeat</li>
</ul>

<p>
but still data labeling is difficult. Thus, this is also not seem much in practise.
</p></li>
</ul></li>
</ul>


<div id="org8fb671e" class="figure">
<p><img src="data/deep_reinforcement_learning_cs_285_fall_2021/dagger_dataset_aggregation-20230710083707.png" alt="dagger_dataset_aggregation-20230710083707.png" />
</p>
<p><span class="figure-number">Figure 6: </span>DAgger: Dataset Aggregation</p>
</div>
</div>
</div>

<div id="outline-container-%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%202%2C%20Part%202%20%5C%5B988gLurg01U%5C%5D.mp4%5D%5BL2P2%5D%5D" class="outline-3">
<h3 id="%5B%5Bmpv%3Acloud%2FDeepRL%20Sergey%20Levine%2FCS%20285%EF%BC%9A%20Lecture%202%2C%20Part%202%20%5C%5B988gLurg01U%5C%5D.mp4%5D%5BL2P2%5D%5D"><span class="section-number-3">6.2.</span> <a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 2 [988gLurg01U].mp4">L2P2</a></h3>
<div class="outline-text-3" id="text-6-2">
<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 3 [H_z7vxGhsQk].mp4">L2P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 4 [ajAaM5FMRz4].mp4">L2P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 5 [e2PpdPC34kI].mp4">L2P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 2, Part 6 [nM9f-5oQ86Y].mp4">L2P6</a>
</p>
</div>
</div>
</div>

<div id="outline-container-Links" class="outline-2">
<h2 id="Links"><span class="section-number-2">7.</span> Links</h2>
<div class="outline-text-2" id="text-7">
<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 10, Part 1 [4SL0DnxC1GM].mp4">L10P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 10, Part 2 [pd9mKcH4kkk].mp4">L10P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 10, Part 3 [gqTE8-tH3Iw].mp4">L10P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 10, Part 4 [PHC2dm4E_VQ].mp4">L10P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 10, Part 5 [4Km05TctgNw].mp4">L10P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 11, Part 1 [LkTmiylbHYk].mp4">L11P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 11, Part 2 [pSvjDO1B9WY].mp4">L11P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 11, Part 3 [zKiyNUSLGbQ].mp4">L11P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 11, Part 4 [7OjR-DSS7dM].mp4">L11P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 11, Part 5 [2EWicx9uP1Q].mp4">L11P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 12, Part 1 [5GJkqMFgADw].mp4">L12P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 12, Part 2 [cVnTRwrY4lE].mp4">L12P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 12, Part 3 [wXcu6xMs9BM].mp4">L12P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 12, Part 4 [DszxsbAl8Eo].mp4">L12P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 13, Part 1 [RTLeJrp5Yp4].mp4">L13P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 13, Part 2 [bb3Aus4R654].mp4">L13P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 13, Part 3 [VR6no95qNts].mp4">L13P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 13, Part 4 [85_0i1Ug1kg].mp4">L13P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 13, Part 5 [9Y9lHFgiJZ0].mp4">L13P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 13, Part 6 [40-_EclzZ5Q].mp4">L13P6</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 14, Part 1 [HnV3ed8wqPA].mp4">L14P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 14, Part 2 [FxzreFYUkxo].mp4">L14P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 14, Part 3 [N9I0jstOWCc].mp4">L14P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 14, Part 4 [9O3GMntSL80].mp4">L14P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 16, Part 1 [Gelfx1FJLu4].mp4">L16P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 16, Part 2 [c22anX3wiSo].mp4">L16P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 16, Part 3 [RsagaGXSN_k].mp4">L16P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 16, Part 4 [IE4kUR3yN8o].mp4">L16P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 17, Part 1 [KUDKSxflwYI].mp4">L17P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 17, Part 2 [SlxQhZWQ62o].mp4">L17P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 17, Part 3 [nctFgWfN6yA].mp4">L17P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 18, Variational Inference, Part 1 [UTMpM4orS30].mp4">L18P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 18, Variational Inference, Part 2 [VWb0ZywWpqc].mp4">L18P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 18, Variational Inference, Part 3 [4LuA5m5Hsxc].mp4">L18P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 18, Variational Inference, Part 4 [nRji3pMCCPo].mp4">L18P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 19, Control as Inference, Part 1 [MzVlYYGtg0M].mp4">L19P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 19, Control as Inference, Part 2 [1NgU3EKHlpY].mp4">L19P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 19, Control as Inference, Part 3 [PAvT1Ypvmm4].mp4">L19P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 19, Control as Inference, Part 4 [LyG1lLf1BQc].mp4">L19P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 19, Control as Inference, Part 5 [QYY94MXgmnc].mp4">L19P5</a>
</p>

<p>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 21, Transfer Learning, Part 3 [D3KWk4VaLSs].mp4">L21P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 21, Transfer Learning, Part 4 [gdd7QMBbXNk].mp4">L21P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 21, Transfer Learning, Part 5 [oVEvw_0Qqjc].mp4">L21P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 22, Meta-Learning, Part 1 [mftNApIM1Yc].mp4">L22P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 22, Meta-Learning, Part 2 [tKOnUVhFZ5o].mp4">L22P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 22, Meta-Learning, Part 3 [UY8Az7kcL7Q].mp4">L22P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 22, Meta-Learning, Part 4 [w9KAmvUA9WI].mp4">L22P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 22, Meta-Learning, Part 5 [RmkPSD92-Ro].mp4">L22P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 23, Open Problems, Part 1 [3ezmV6y6WUw].mp4">L23P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 23, Open Problems, Part 2 [i25Vb1LB0DE].mp4">L23P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 23, Open Problems, Part 3 [GArIRCAeSiQ].mp4">L23P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 4, Part 1 [jds0Wh9jTvE].mp4">L4P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 4, Part 2 [Cip5UeGrCEE].mp4">L4P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 4, Part 3 [Pua9zO_YmKA].mp4">L4P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 4, Part 4 [eG9-F4r5k70].mp4">L4P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 4, Part 5 [dFqoGAyofUQ].mp4">L4P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 4, Part 6 [hfj9mS3nTLU].mp4">L4P6</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 5, Part 1 [GKoKNYaBvM0].mp4">L5P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 5, Part 2 [VSPYKXm_hMA].mp4">L5P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 5, Part 3 [VgdSubQN35g].mp4">L5P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 5, Part 4 [KZd508qGFt0].mp4">L5P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 5, Part 5 [QRLDAQbWc78].mp4">L5P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 5, Part 6 [PEzuojy8lVo].mp4">L5P6</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 6, Part 1 [wr00ef_TY6Q].mp4">L6P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 6, Part 2 [KVHtuwVhULA].mp4">L6P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 6, Part 3 [g4_2IfZqDLI].mp4">L6P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 6, Part 4 [quRjnkj-MA0].mp4">L6P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 6, Part 5 [A99gFMZPw7w].mp4">L6P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 7, Part 1 [pP_67mTJbGw].mp4">L7P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 7, Part 2 [QUbuBEY12u0].mp4">L7P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 7, Part 3 [Mz7XweEMCVI].mp4">L7P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 7, Part 4 [9bOurz4aCbA].mp4">L7P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 8, Part 1 [7-D8RL3D6CI].mp4">L8P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 8, Part 2 [lqC9w532erw].mp4">L8P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 8, Part 3 [oKfUMzfpAw0].mp4">L8P3</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 8, Part 4 [oMUSn1eRm7A].mp4">L8P4</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 8, Part 5 [Q-Qwjz8Zmh0].mp4">L8P5</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 8, Part 6 [cmGSnu-PIwU].mp4">L8P6</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 9, Part 1 [ySenCHPsKJU].mp4">L9P1</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 9, Part 2 [LtAt5M_a0dI].mp4">L9P2</a>
<a href="cloud/DeepRL Sergey Levine/CS 285： Lecture 9, Part 3 [WuPauZgX7BM].mp4">L9P3</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: Deep Reinforcement Learning: CS 285 Fall 2021">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div><a href="https://bpanthi977.github.io/braindump/data/rss.xml"><img src="https://bpanthi977.github.io/braindump/data/rss.png" /></a>
</div>
</body>
</html>
