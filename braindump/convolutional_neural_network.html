<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Convolutional Neural Network</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="./index.html"> UP </a>
 |
 <a accesskey="H" href="../index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-03-26 Sun]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">Convolutional Neural Network</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#ID-27AA0284-6683-4A97-B54B-9620A790CECC">1. Depthwise Separable Convolutions</a>
<ul>
<li><a href="#How%20it%20work%3F">1.1. How it work?</a></li>
<li><a href="#Should%20the%20first%20layer%20for%20RGB%20input%20be%20DepthWise%20Separable%20Convolution%3F">1.2. Should the first layer for RGB input be DepthWise Separable Convolution?</a></li>
</ul>
</li>
</ul>
</div>
</div>
<ul class="org-ul">
<li><a href="green_function.html#ID-D20C67C4-6A9A-4701-B327-00251396EC4C">Convolution</a></li>
<li>Visualize convolutional layer: <a href="https://ezyang.github.io/convolution-visualizer/">https://ezyang.github.io/convolution-visualizer/</a></li>
</ul>
<div id="outline-container-ID-27AA0284-6683-4A97-B54B-9620A790CECC" class="outline-2">
<h2 id="ID-27AA0284-6683-4A97-B54B-9620A790CECC"><span class="section-number-2">1.</span> Depthwise Separable Convolutions</h2>
<div class="outline-text-2" id="text-1">
<p>
Depthwise Separable Convolutions can act as drop in replacement for Conv2D and improve the accuracy while reducing the number of parameters and operations. 
</p>

<p>
This layer performs a spatial convolution on each channel of its input, independently, before mixing output channels via a pointwise convolution (a 1 × 1 convolution). 
</p>

<p>
<a href="patches_are_all_you_need.html#ID-A0683583-8F59-4751-9641-9127AE8CF019">Patches Are All You Need?</a> paper seems to be doing the same thing. But has GeLUs, Batchnorms and residual connection in the mix with both depthwise and pointwise convolution. i.e. depthwise convolution doesn't immediately follow pointwise convolution. 
</p>
</div>
<div id="outline-container-How%20it%20work%3F" class="outline-3">
<h3 id="How%20it%20work%3F"><span class="section-number-3">1.1.</span> How it work?</h3>
<div class="outline-text-3" id="text-1-1">
<p>
(from <a href="deep_learning_with_python_francois_chollet.html#ID-857CAF91-5AFC-4F9E-8BD6-0A1804942B7B">Deep Learning with Python - François Chollet</a> pg. 258) 
</p>
<ul class="org-ul">
<li>It is equivalent to separating the learning of spatial features and the learning of channel-wise features.</li>

<li>the assumption is that <code>spatial locations in intermediate activations are highly correlated, but different channels are highly independent</code>.</li>
<li>this assumption serves as a useful prior that helps the model make more efficient use of its training data.</li>
</ul>
</div>
</div>
<div id="outline-container-Should%20the%20first%20layer%20for%20RGB%20input%20be%20DepthWise%20Separable%20Convolution%3F" class="outline-3">
<h3 id="Should%20the%20first%20layer%20for%20RGB%20input%20be%20DepthWise%20Separable%20Convolution%3F"><span class="section-number-3">1.2.</span> Should the first layer for RGB input be DepthWise Separable Convolution?</h3>
<div class="outline-text-3" id="text-1-2">
<p>
No. Because the assumption that underlies separable convolution, “feature channels are largely independent,” does not hold for RGB images! Red, green, and blue color channels are actually highly correlated in natural images. 
</p>

<p>
As such, the first layer has to be the usual Conv2D layer.
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: Convolutional Neural Network">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div><a href="https://bpanthi977.github.io/braindump/data/rss.xml"><img src="https://bpanthi977.github.io/braindump/data/rss.png" /></a>
</div>
</body>
</html>
