<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Training Recurrent Nets is Optimization Over Programs</title>
<meta name="author" content="Bibek Panthi" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<link rel="stylesheet" type="text/css" href="../css/braindump.css" />
<script src="../js/counters.js" type="text/javascript"></script>
<script src="../js/URI.js" type="text/javascript"></script>
<script src="../js/pages.js" type="text/javascript"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="./index.html"> UP </a>
 |
 <a accesskey="H" href="../index.html"> HOME </a>
</div><div id="preamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">[2023-03-19 Sun]</span></span></p>
</div>
<div id="content" class="content">
<h1 class="title">Training Recurrent Nets is Optimization Over Programs</h1>
<ul class="org-ul">
<li><p>
<b>If training vanilla neural nets is <a href="optimization_problem.html#ID-2A25B7D8-B49D-4491-A7B6-3A4318049D78">optimization</a> over functions, training <a href="Recurrent neural network.html#ID-62e97a52-1804-4948-91e4-bede2027d3d5">recurrent nets</a> is optimization over programs.</b> 
</p>

<p>
RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, <span class="underline">RNNs essentially describe programs</span>.
</p>

<p>
In fact, it is known that <span class="underline">RNNs are Turing-Complete</span> in the sense that they can to simulate arbitrary programs (with proper weights).
</p>

<p>
<span class="underline">But similar to universal approximation theorems</span> for neural nets you shouldnâ€™t read too much into this. In fact, forget I said anything.
</p>

<p>
[from <a href="private/the_unreasonable_effectiveness_of_recurrent_neural_networks_andrej_karpathy.html#ID-C87D99C4-20AF-4AF5-905F-ECA82BB7AB54">The Unreasonable Effectiveness of Recurrent Neural Networks - Andrej Karpathy</a>]
</p></li>
</ul>

<hr />
<h3>Backlinks</h3>

<ul class="org-ul">
<li><a href="lstm.html#ID-5A05C89D-F75E-4B28-B8A7-3A68D1B6C5CA">LSTM</a></li>
<li><a href="meta_learning.html#ID-8e4ac4d5-5881-46e6-9ee6-e0d5160a43b0">Meta Learning</a></li>
<li><a href="Recurrent neural network.html#ID-62e97a52-1804-4948-91e4-bede2027d3d5">Recurrent neural network</a></li>
</ul>
</div>
<div id="postamble" class="status">
<hr/>You can send your feedback, queries <a href="mailto:bpanthi977@gmail.com?subject=Feedback: Training Recurrent Nets is Optimization Over Programs">here</a><span id="visits"></span><span id="claps"></span><div id="claps-message"></div><a href="https://bpanthi977.github.io/braindump/data/rss.xml"><img src="https://bpanthi977.github.io/braindump/data/rss.png" /></a>
</div>
</body>
</html>
